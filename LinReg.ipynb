{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from torch.multiprocessing import Process\n",
    "import cProfile\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfSamples = 1000\n",
    "numberOfFeatures = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 10, numberOfSamples).reshape(-1, 1) # we want samples between 1 and -1\n",
    "x = torch.from_numpy(x).float()\n",
    "y = x * 3 + torch.rand(numberOfSamples).reshape(-1, 1) * 7 + 10* torch.cos(1.2*x)\n",
    "plt.scatter(x, y)\n",
    "#Axes3D.scatter(x.numpy(), x.numpy(), y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def model(x, w, b):\n",
    "    return x @ w.t() + b\n",
    "\n",
    "# MSE loss\n",
    "def mse(t1, t2):\n",
    "    diff = t1 - t2\n",
    "    return torch.sum(diff * diff) / diff.numel()\n",
    "\n",
    "def batch_iter(y, tx, batch_size, num_batches=1):\n",
    "    data_size = len(y)\n",
    "    shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "    shuffled_y = y[shuffle_indices]\n",
    "    shuffled_tx = tx[shuffle_indices]\n",
    "    for batch_num in range(num_batches):\n",
    "        start_index = batch_num * batch_size\n",
    "        end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "        if start_index != end_index:\n",
    "            yield shuffled_y[start_index:end_index], shuffled_tx[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_solution(w, b):\n",
    "    plt.scatter(x, y)\n",
    "    plt.scatter(x, x @ w.t().detach() + b.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(targets, inputs, batch_size, max_iter, λ=5e-3):\n",
    "    losses = []\n",
    "    w = torch.randn(1, numberOfFeatures, requires_grad=True)\n",
    "    b = torch.randn(numberOfFeatures, requires_grad=True)\n",
    "    acc_loss = 0\n",
    "    i = 0\n",
    "    for ybatch, xbatch in batch_iter(targets, inputs, batch_size, max_iter):\n",
    "        preds = model(xbatch, w, b)\n",
    "        loss = mse(preds, ybatch)\n",
    "        print('epoch', i, \" loss=\", loss)\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            w -= w.grad * λ\n",
    "            b -= b.grad * λ\n",
    "            w.grad.zero_()\n",
    "            b.grad.zero_()\n",
    "        i += 1\n",
    "    return w, b\n",
    "plot_solution(*sgd(y, x, 5, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(tensor):\n",
    "    N = list(tensor.size())[0]\n",
    "    Q = torch.zeros(N, dtype=bool)\n",
    "    Q = tensor > 0\n",
    "    return Q\n",
    "def unquantize(tensor):\n",
    "    tensor = tensor.type(torch.FloatTensor)\n",
    "    tensor[tensor == 0] = -1\n",
    "    return tensor # * data_scale\n",
    "\n",
    "\"\"\"\n",
    "GPU i is responsible for chunk i\n",
    "\"\"\"\n",
    "def ms_allreduce(tensor, chunksize=1):\n",
    "    r = dist.get_rank()\n",
    "    arraySize=tensor.size()\n",
    "    acc = torch.zeros(arraySize)\n",
    "    acc[r*chunksize:(r+1)*chunksize] = tensor[r*chunksize:(r+1)*chunksize]\n",
    "    reqs = []\n",
    "    #\"Naive all-reduce\"\n",
    "    for i in range(dist.get_world_size()): # K steps\n",
    "        if i != r:\n",
    "            reqs += [dist.isend(tensor=quantize(tensor[i*chunksize:(i+1)*chunksize]), dst=i)] # K concurrent transfers\n",
    "    for i in range(dist.get_world_size()): # K steps\n",
    "        if i != r:\n",
    "            recv = torch.zeros(arraySize, dtype=bool)\n",
    "            dist.recv(tensor=recv[r*chunksize:(r+1)*chunksize],src=i) # K / ??? values...\n",
    "            acc += unquantize(recv)\n",
    "    for req in reqs:\n",
    "        req.wait()\n",
    "    reqs = []\n",
    "    #\"Naive all-gather\"\n",
    "    for i in range(dist.get_world_size()):\n",
    "        if i != r:\n",
    "            reqs += [dist.isend(tensor=quantize(acc[r*chunksize:(r+1)*chunksize]),dst=i)]\n",
    "    #\"Naive all-gather\"\n",
    "    for i in range(dist.get_world_size()):\n",
    "        if i != r:\n",
    "            recv = torch.zeros(arraySize, dtype=bool)\n",
    "            dist.recv(tensor=recv[i*chunksize:(i+1)*chunksize], src=i)\n",
    "            acc[i*chunksize:(i+1)*chunksize] += unquantize(recv[i*chunksize:(i+1)*chunksize])\n",
    "    for req in reqs:\n",
    "        req.wait()\n",
    "    tensor[:] = acc[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_sgdq(rank, size, group, targets, inputs, batch_size, max_iter, λ=1e-2):\n",
    "    losses = []\n",
    "    w = torch.randn(1, numberOfFeatures, requires_grad=True)\n",
    "    b = torch.randn(numberOfFeatures, requires_grad=True)\n",
    "    acc_loss = 0\n",
    "    i = 0\n",
    "    for ybatch, xbatch in batch_iter(targets, inputs, batch_size, max_iter):\n",
    "        preds = model(xbatch, w, b)\n",
    "        loss = mse(preds, ybatch)\n",
    "        print('epoch(rank[', rank,'])', i, \" loss=\", loss)\n",
    "        loss.backward()\n",
    "        error_G = torch.zeros(w.size())\n",
    "        error_b = torch.zeros(b.size())\n",
    "        with torch.no_grad():\n",
    "            G = w.grad.clone() + error_G\n",
    "            ms_allreduce(w.grad)\n",
    "            error_G = G - w.grad / size\n",
    "            B = b.grad.clone() + error_b\n",
    "            ms_allreduce(b.grad)\n",
    "            error_b = B - b.grad / size \n",
    "            #print(rank, ': ', error, ' = ', G)\n",
    "            #print('rank[', rank, '] has ', w.grad)\n",
    "            w -= G * λ\n",
    "            b -= B * λ\n",
    "            w.grad.zero_()\n",
    "            b.grad.zero_()\n",
    "        i += 1\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_processes(rank, size, fn, backend='gloo'):\n",
    "    \"\"\" Initialize the distributed environment. \"\"\"\n",
    "    os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
    "    os.environ['MASTER_PORT'] = '29500'\n",
    "    dist.init_process_group(backend, rank=rank, world_size=size+1)\n",
    "    fn(rank, size+1)\n",
    "    return 3\n",
    "def run(rank, size):\n",
    "    print(rank, 'running...')\n",
    "    group = dist.new_group(list(range(size)))\n",
    "    assert numberOfSamples % size == 0\n",
    "    C = int(numberOfSamples / size)\n",
    "    f, t = rank*C, (rank+1)*C\n",
    "    w, b = dist_sgdq(rank, size, group, y[f:t], x[f:t], 5, 100) #should avg instead?\n",
    "    print('Solution rank', rank,{'w': w, 'b': b})\n",
    "    print(w, b)\n",
    "    #dist.send(tensor=w, dst=)\n",
    "\n",
    "size = 2\n",
    "processes = []\n",
    "for rank in range(size):\n",
    "    p = Process(target=init_processes, args=(rank, size, run))\n",
    "    p.start()\n",
    "    processes.append(p)\n",
    "    \n",
    "#os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
    "#os.environ['MASTER_PORT'] = '29500'\n",
    "#dist.init_process_group('gloo', rank=size, world_size=size+1)\n",
    "for p in processes:\n",
    "    p.join()\n",
    "#plot_solution(ww['0'], bb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_solution(torch.tensor([1.0072]), torch.tensor([3.7367]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bds",
   "language": "python",
   "name": "bds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
