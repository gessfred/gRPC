{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from FlameGraphs\n",
    "Flamegraphs are really nice to analyse function in development phase, but not the most natural format for production automatic CICD benchmarking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_runtimes = np.array([0.642066478729248,\n",
    "                    2.280177593231201,\n",
    "                    20.51885223388672,\n",
    "                    307.2343645095825])\n",
    "baseline_runtimes\n",
    "allreduce_runtimes = np.array([\n",
    "    0.9886195659637451,\n",
    "    2.6663870811462402,\n",
    "    30.583645582199097,\n",
    "    515.5396280288696\n",
    "])\n",
    "allreduce_quant24_runtimes = np.array([\n",
    "    0.855358362197876,\n",
    "    0.8036544322967529,\n",
    "    3.2721290588378906,\n",
    "    100.87990117073059\n",
    "])\n",
    "allreduce_numpy_runtimes = np.array([\n",
    "    1.6837677955627441,\n",
    "    6.494603157043457,\n",
    "    90.2047004699707,\n",
    "    1236.9328877925873\n",
    "])\n",
    "all_reduce_ext_runtimes = np.array([\n",
    "    1.0342988967895508,\n",
    "    2.67451810836792,\n",
    "    19.48147678375244,\n",
    "    300.335649728775\n",
    "])\n",
    "runtimes = {\n",
    "    'np': allreduce_numpy_runtimes,\n",
    "    'ext': all_reduce_ext_runtimes,\n",
    "    'par24': allreduce_quant24_runtimes,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breakdown_of(graph, run='run:42'):\n",
    "    with open(graph) as svg:\n",
    "        quantization = [':139', ':144', ':154', ':158']\n",
    "        quantization = list(map(lambda s: 'allreduce_quant'+s, quantization))\n",
    "        communication = ['isend:', 'recv:']\n",
    "        soup = BeautifulSoup(svg, 'lxml-xml')\n",
    "        titles = soup.findAll('title')\n",
    "        def percentage_of(trace):\n",
    "            matches = [title for title in titles if title.string.find(trace) != -1]\n",
    "            matches = list(map(lambda tag: tag.string, matches))\n",
    "            #percentage = sum(list(map(lambda trace: float(''.join(list(trace.split(':')[-1].split(',')[1])[:-2])), matches)))\n",
    "            percentages = list(map(lambda trace: float(''.join(trace.split(':')[-1].split(',')[-1][:-2])), matches))\n",
    "            return sum(percentages)\n",
    "        bias = percentage_of(run)\n",
    "        communication = sum([percentage_of(part) for part in communication]) * 100 / bias\n",
    "        quantization = sum(list(map(percentage_of, quantization))) * 100 / bias\n",
    "        return communication, quantization, 100 - communication - quantization\n",
    "#np.array([np.array() for fn in ['np']])\n",
    "df = {\n",
    "    'function': [],\n",
    "    'input_size': [],\n",
    "    'computation': [],\n",
    "    'communication': [],\n",
    "    'quantization': [],\n",
    "    'total': [],\n",
    "}\n",
    "for k, input_size in enumerate(range(14, 27, 4)):\n",
    "    df['function'].append('baseline')\n",
    "    df['input_size'].append(input_size)\n",
    "    df['computation'].append(0)\n",
    "    df['communication'].append(0)\n",
    "    df['quantization'].append(0)\n",
    "    df['total'].append(baseline_runtimes[k])\n",
    "for fn in ['np', 'ext', 'par24']:\n",
    "    for k, input_size in enumerate(range(14, 27, 4)):\n",
    "        com, q, cmp = breakdown_of('exp17dec/{}-{}.svg'.format(fn, input_size))\n",
    "        rt = runtimes[fn][k]\n",
    "        df['function'].append(fn)\n",
    "        df['input_size'].append(input_size)\n",
    "        df['computation'].append(cmp * rt / 100)\n",
    "        df['communication'].append(com * rt / 100)\n",
    "        df['quantization'].append(q * rt / 100)\n",
    "        df['total'].append((cmp+com+q)*rt/100)\n",
    "\n",
    "df = pd.DataFrame.from_dict(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: is log scale non-sensical?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barWidth = 0.6\n",
    "spacing = 0.1\n",
    "numberOfInputSizes = len(df[df.function == 'np'])\n",
    "baselineTicks = np.arange(numberOfInputSizes) * 4\n",
    "npTicks = [x + barWidth + spacing for x in baselineTicks]\n",
    "extTicks = [x + barWidth  +spacing for x in npTicks]\n",
    "par24Ticks = [x + barWidth + spacing for x in extTicks]\n",
    "comm = 'purple'\n",
    "comp = 'yellow'\n",
    "quant = 'blue'\n",
    "def part3plot(ax, ticks, df, label):\n",
    "    ax.bar(ticks, df.communication, width=barWidth, color=comm)\n",
    "    ax.bar(ticks, df.computation, width=barWidth, color=comp, bottom=np.array(df.communication))\n",
    "    ax.bar(ticks, df.quantization, width=barWidth, color=quant, bottom=np.array(df.computation))\n",
    "#baseline\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_yscale('log')\n",
    "ax.bar(baselineTicks, df[df['function'] == 'baseline'].total, width=barWidth, edgecolor='white', label='baseline', color='#7f6d5f')\n",
    "#numpy\n",
    "npy = df[df['function'] == 'np']\n",
    "part3plot(ax, npTicks, npy, 'numpy')\n",
    "ext = df[df['function'] == 'ext']\n",
    "part3plot(ax, extTicks, ext, 'extension')\n",
    "par24 = df[df['function'] == 'par24']\n",
    "part3plot(ax, par24Ticks, par24, 'parallel')\n",
    "plt.xticks(baselineTicks+1.5*barWidth + spacing, ('2**14', '2**18', '2**22', '2**26'))\n",
    "plt.legend()\n",
    "#ax.bar(extTicks, ext.communication, width=barWidth, color=comm)\n",
    "#ax.bar(extTicks, ext.computation, width=barWidth, color=comp, bottom=ext.communication)\n",
    "#ax.bar(extTicks, ext.quantization, width=barWidth, color=quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = df[df['input_size'] == 18]\n",
    "print(d2.sort_values('function'))\n",
    "x = np.arange(4)\n",
    "width = 0.5\n",
    "plt.bar(x, d2.computation, width=width, color='#9cfc97')\n",
    "plt.bar(x, d2.communication, bottom=np.array(d2.computation), width=width, color='#6ba368')\n",
    "plt.bar(x, d2.quantization, bottom=np.array(d2.communication), width=width, color='#515b3a')\n",
    "plt.bar(x, d2.total-d2.computation-d2.communication-d2.quantization, bottom=np.array(d2.quantization), width=width, color='#353d2f')\n",
    "plt.xticks(x, ['baseline', 'numpy', 'extension', 'parallel'])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking of parallel quantize extension (v1)\n",
    "Benchmarked by quantizing and unquantizing a tensor of 1 mio elements for 10k shots.\n",
    "```python\n",
    "def benchmarkQ(iters):\n",
    "    quantize, unquantize = quantizy('ext_par')\n",
    "    tensor = torch.one(2**20)\n",
    "    \n",
    "    for numberOfThreads in [1, 2, 4, 8, 16, 24, 32, 48]:\n",
    "        start = time.time()\n",
    "        for _ in range(iters):\n",
    "            unquantize(quantize(tensor, numberOfThreads), numberOfThreads)\n",
    "        runtime = time.time() - start\n",
    "        print('{}: {}'.format(numberOfThreads, runtime))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    1: 33.79728627204895,\n",
    "    2: 36.45126271247864,\n",
    "    4: 30.421996116638184,\n",
    "    8: 23.117279529571533,\n",
    "    16: 14.099677801132202,\n",
    "    24: 2.432234048843384,\n",
    "    32: 16.60316228866577,\n",
    "    48: 86.07797956466675\n",
    "}\n",
    "numberOfThreads = list(data)\n",
    "runtimes = list(data.values())\n",
    "df = pd.DataFrame.from_dict({'numberOfThreads': numberOfThreads, 'runtimes': runtimes})\n",
    "#sns.set(style=\"whitegrid\")\n",
    "#ax = sns.barplot(x='numberOfThreads', y='runtimes', data=df)\n",
    "#ax.get_figure().savefig('ext_par_barplot.png')\n",
    "fig = px.bar(df, x='numberOfThreads', y='runtimes')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict({\n",
    "    'function': ['all-reduce-unquantized']*4+['all-reduce-np']*4+['all-reduce-c++']*4+['all-reduce-c++--t4']*4+['all-reduce-c++--t24']*4,\n",
    "    'input_sizes': [14, 18, 22, 26]*5,\n",
    "    'runtimes': [2.8797550201416016, 3.628589153289795, 34.27912616729736, 586.1691422462463,\n",
    "                5.380201578140259, 11.700040578842163, 105.51217818260193, 1355.664867401123,\n",
    "                3.988344192504883, 7.569454193115234, 90.7022819519043, 1620.5233752727509,\n",
    "                3.2412919998168945, 20.209644079208374, 51.957091093063354, 692.5020751953125,\n",
    "                1.902247667312622, 2.1534981727600098, 8.664215326309204, 269.09099531173706],\n",
    "    'communication': [0]*20,\n",
    "    'quantization': [0]*20,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (grpc)",
   "language": "python",
   "name": "grpc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
